{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. _nb_de:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. meta::\n",
    "   :description: Differential Evolution (DE) is an Evolutionary Algorithm (EA) originally designed for solving optimization problems over continuous domains. It has a simple implementation yet a great problem-solving quality, which makes it one of the most popular population-based algorithms, with several successful applications reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. meta::\n",
    "   :keywords: Differential Evolution, DE,  Multi-modal Optimization, Nature-inspired Algorithm, Single-objective Optimization, Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DE: Differential Evolution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differential evolution <cite data-cite=\"de_article\"></cite> is an Evolutionary Algorithm (EA) originally designed for solving optimization problems over continuous domains. It has a simple implementation yet a great problem-solving quality, which makes it one of the most popular population-based algorithms, with several successful applications reported.\n",
    "\n",
    "From its original conception, DE was designed to fulfill some requirements that have made it particularly useful:\n",
    "\n",
    "- Ability to handle non-differentiable, nonlinear, and multimodal cost functions.\n",
    "- Parallelizability to cope with computationally intensive cost functions.\n",
    "- Ease of use: few control variables to steer the minimization. These variables should also be robust and easy to choose.\n",
    "- Good convergence properties: consistent convergence to the global minimum in consecutive independent trials.\n",
    "\n",
    "Several DE variants have been proposed in the literature (including multi-objective variants). Most of them share some common operations when producing offsprings for the next generation. A detailed overview on DE mechanisms can be found at <cite data-cite=\"de_book\"></cite>.\n",
    "\n",
    "At each generation, $N$ new individuals (same as population size) are produced by operations originally defined as *mutation* and *crossover*. Notice the *mutation* in DE is conceptually different from the usual definition in genetic algorithms and in pymoo it is implemented as a *Crossover* operator.\n",
    "\n",
    "Several reproduction schemes have been proposed for DE. Usually, they are denoted DE/*x*/*y*/*z*, in which *x* corresponds to the mutation *parent selection* scheme, *y* to the number of difference vectors in *mutation*, and *z* to the *crossover* strategy.\n",
    "\n",
    "Probably the most popular mutation scheme is the DE/rand/1, represented by the equation below.\n",
    "\n",
    "$$\n",
    "\\boldsymbol{v}_i=\\boldsymbol{x}_{r1}+F(\\boldsymbol{x}_{r2}-\\boldsymbol{x}_{r3})\n",
    "$$\n",
    "\n",
    "In which, $v_i$ is the mutant vector of index $i$; and $r1$, $r2$, and $r3$ are mutually different indices and also different from $i$. The difference between individual $r2$ and $r3$ scaled by the $F$ parameter is added to $r1$.\n",
    "\n",
    "The *crossover* operation occurs between a given mutant vector and its corresponding parent of same index. The most usual is the binomial (bin) crossover, given by the equation below. Notice that it is mandatory that at least one attribute $j$ of $u$ is inherited from $v$.\n",
    "\n",
    "$$\n",
    "u_{i, j}\n",
    "\\begin{cases}\n",
    " v_{i, j} & \\text{ if } \\text{ rand }(0, 1)_{i, j} < CR \\\\ \n",
    " x_{i, j} & \\text{ if } \\text{ rand }(0, 1)_{i, j} \\geq CR \\; \\lor \\; j = j_{rand}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This creation of a new individual in the DE/rand/1/bin scheme is represented below:\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://github.com/anyoptimization/pymoo-data/blob/main/docs/images/de_mating.png?raw=true\" width=\"350\">\n",
    "</div>\n",
    "\n",
    "\n",
    "A great tutorial and more detailed information can be found [here](https://web.archive.org/web/20190928024126/http://www1.icsi.berkeley.edu/~storn/code.html). The following guideline is copied from the description there (variable names are modified):\n",
    "\n",
    "If you are going to optimize your own objective function with DE, you may try the following classical settings for the input file first: Choose method e.g. DE/rand/1/bin, set the population size $N$ to 10 times the number of parameters, select weighting factor `F=0.8`, and crossover constant `CR=0.9`. Recently, it has been found that selecting $F$ from the interval (0.5, 1.0) randomly for each generation or each difference vector, a technique called dither, improves convergence behavior significantly, especially for noisy objective functions. \n",
    "\n",
    "It has also been found that setting $CR$ to a low value, e.g., `CR=0.2` helps to optimize separable functions since it fosters the search along the coordinate axes. It can also be helpful to avoid premature convergence in some complex problems. On the contrary, this choice is not effective if parameter interdependence is encountered, which frequently occurs in real-world optimization problems rather than artificial test functions. So for parameter interdependence, the choice of $CR$ between 0.7 and 0.9 is likely to be more appropriate.\n",
    "\n",
    "Another interesting empirical finding is that raising $N$ above, say, 40 does not substantially improve the convergence, independent of the number of parameters. It is worthwhile to experiment with these suggestions. Ensure that you initialize your parameter vectors by exploiting their full numerical range, i.e., if a parameter is allowed to exhibit values in the range (-100, 100), it is a good idea to pick the initial values from this range instead of unnecessarily restricting diversity.\n",
    "\n",
    "Keep in mind that different problems often require different settings for $N$, $F$, and $CR$ (have a look into the different papers to get a feeling for the settings). If you still get misconvergence, you might want to try a different method. We mostly use 'DE/rand/1/...' or 'DE/best/1/...'. The crossover method is not so crucial, although Ken Price claims that binomial is never worse than exponential. In the case of misconvergence, also check your choice of objective function. There might be a better one to describe your problem. Any knowledge that you have about the problem should be worked into the objective function. A good objective function can make all the difference.\n",
    "\n",
    "And this is how DE can be used:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T02:42:32.165406Z",
     "iopub.status.busy": "2022-08-01T02:42:32.164895Z",
     "iopub.status.idle": "2022-08-01T02:42:34.859580Z",
     "shell.execute_reply": "2022-08-01T02:42:34.858677Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymoo.algorithms.soo.nonconvex.de import DE\n",
    "from pymoo.problems import get_problem\n",
    "from pymoo.optimize import minimize\n",
    "\n",
    "\n",
    "problem = get_problem(\"ackley\", n_var=10)\n",
    "\n",
    "\n",
    "algorithm = DE(pop_size=50, variant=\"DE/rand/1/bin\", CR=0.5, F=(0.3, 0.8))\n",
    "\n",
    "res = minimize(problem,\n",
    "               algorithm,\n",
    "               (\"n_gen\", 300),\n",
    "               seed=1,\n",
    "               verbose=False)\n",
    "\n",
    "print(\"Best solution found: \\nX = %s\\nF = %s\" % (res.X, res.F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. autoclass:: pymoo.algorithms.soo.nonconvex.de.DE\n",
    "    :noindex:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
